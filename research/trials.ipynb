{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d1bd2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\patel\\\\OneDrive\\\\Desktop\\\\Projects\\\\CareBot\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a300d747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\patel\\\\OneDrive\\\\Desktop\\\\Projects\\\\CareBot'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e73d480e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patel\\anaconda3\\envs\\carebot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5563ef7",
   "metadata": {},
   "source": [
    "Extracting the Data (Gale Encyclopedia of Medicine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3125fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                              glob='*.pdf',\n",
    "                              loader_cls = PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07f58ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(data = 'data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a024d390",
   "metadata": {},
   "source": [
    "Chunking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2125173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_chunking(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9431c99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the text chunks: 5859\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_chunking(extracted_data)\n",
    "print('Length of the text chunks:', len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c79b2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def donwload_huggingface_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name= 'sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f103d885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patel\\AppData\\Local\\Temp\\ipykernel_55084\\2724969126.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name= 'sentence-transformers/all-MiniLM-L6-v2')\n"
     ]
    }
   ],
   "source": [
    "embeddings = donwload_huggingface_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "371ff449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length : 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello World!\")\n",
    "print('length :' , len(query_result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9512f2b4",
   "metadata": {},
   "source": [
    "Creating Indexes using pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b04a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n",
    "\n",
    "\n",
    "pc = Pinecone(api_key = PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"carebot\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric = 'cosine',\n",
    "        spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11825745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff94274",
   "metadata": {},
   "source": [
    "Creating Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e13d8856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vs = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeea547c",
   "metadata": {},
   "source": [
    "Loading the Vector Database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87200edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x26ff6520dc0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")\n",
    "vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc2b23a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vs.as_retriever(search_type='similarity', search_kwargs={'k':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d10e622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='49b66d04-eca2-4815-9c54-1ee3f3c18d49', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 39.0, 'page_label': '40', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'data\\\\Medical_book.pdf', 'total_pages': 637.0}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 226\\nAcne\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 26'),\n",
       " Document(id='023e470d-868e-43ea-a1d2-1330dcc22a7b', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 37.0, 'page_label': '38', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'data\\\\Medical_book.pdf', 'total_pages': 637.0}, page_content='Acidosis see Respiratory acidosis; Renal\\ntubular acidosis; Metabolic acidosis\\nAcne\\nDefinition\\nAcne is a common skin disease characterized by\\npimples on the face, chest, and back. It occurs when the\\npores of the skin become clogged with oil, dead skin\\ncells, and bacteria.\\nDescription\\nAcne vulgaris, the medical term for common acne, is\\nthe most common skin disease. It affects nearly 17 million\\npeople in the United States. While acne can arise at any'),\n",
       " Document(id='ad9662ea-51a2-49e4-84cb-9dc7674e06ec', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 38.0, 'page_label': '39', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'data\\\\Medical_book.pdf', 'total_pages': 637.0}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 2 25\\nAcne\\nAcne vulgaris affecting a woman’s face. Acne is the general\\nname given to a skin disorder in which the sebaceous\\nglands become inflamed. (Photograph by Biophoto Associ-\\nates, Photo Researchers, Inc. Reproduced by permission.)\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 25')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = retriever.invoke('What is back Acne?')\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2296eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7a5af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_huggingface.llms.huggingface_endpoint import HuggingFaceEndpoint\n",
    "from langchain_huggingface.chat_models.huggingface import ChatHuggingFace\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "huggingface_repo_id = \"openai/gpt-oss-20b\"\n",
    "\n",
    "def load_llm(huggingface_repo_id):\n",
    "    llm = HuggingFaceEndpoint(\n",
    "        repo_id = huggingface_repo_id,\n",
    "        huggingfacehub_api_token=HF_TOKEN,\n",
    "        task='conversational',  \n",
    "        max_new_tokens = 256,\n",
    "        temperature = 0.3           \n",
    "    )\n",
    "    return llm\n",
    "\n",
    "chat = ChatHuggingFace(llm = load_llm(huggingface_repo_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ff812376",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt =\"\"\"You are an assistant for the question answer tasks. Use the following pieces of retrieved context to answer the question. If you don't \n",
    "    know the asnwer, say that you don't know. Don't provide anything out of the given context. Use three sentences maximum and keep the answer concise. \\n\\n\n",
    "    Context : {context}\n",
    "    Question : {question}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def custom_prompt(system_prompt):\n",
    "    prompt = PromptTemplate(template = system_prompt, input_variables=['context','question'])\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d29ddc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain=RetrievalQA.from_chain_type(\n",
    "    llm = chat,\n",
    "    chain_type = \"stuff\",\n",
    "    retriever = retriever,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5e3a2a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m sorry, but I don’t have that information.\n"
     ]
    }
   ],
   "source": [
    "user_query=input(\"Write Query Here:\")\n",
    "response = qa_chain.invoke({'query': user_query})\n",
    "result = (response['result'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164e3e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains import create_retrieval_chain\n",
    "# from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# system_prompt = (\n",
    "#     \"You are an assistant for the question answer tasks. Use the following pieces of retrieved context to answer the question. If you don't \" \\\n",
    "#     \"know the asnwer, say that you don't know. Use three sentences maximum and keep the answer concise. \\n\\n\"\n",
    "#     \"{context}\"\n",
    "# )\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         ('system', system_prompt),\n",
    "#         ('human', '{input}')\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7622f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.llms import Ollama\n",
    "# llm = Ollama(model = 'mistral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97c4f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
      "  context: RunnableLambda(format_docs)\n",
      "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
      "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for the question answer tasks. Use the following pieces of retrieved context to answer the question. If you don't know the asnwer, say that you don't know. Use three sentences maximum and keep the answer concise. \\n\\n{context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
      "| Ollama(model='mistral')\n",
      "| StrOutputParser() kwargs={} config={'run_name': 'stuff_documents_chain'} config_factories=[]\n"
     ]
    }
   ],
   "source": [
    "# question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "# print(question_answer_chain)\n",
    "# rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b124f131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Acne is a common skin disease characterized by pimples on the face, chest, and back. It occurs when the pores of the skin become clogged with oil, dead skin cells, and bacteria. Acne vulgaris, also known as common acne, is the most prevalent form and affects nearly 17 million people in the U.S.\n"
     ]
    }
   ],
   "source": [
    "# response = rag_chain.invoke({'input': 'What is Acne'})\n",
    "# print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6defbe78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The treatment for back acne can involve topical drugs like tretinoin, benzoyl peroxide, adapalene, or salicylic acid to reduce the formation of new comedones. Shampooing often, wearing hair off the face, avoiding foods that trigger flare-ups, and reducing stress are also recommended. Additionally, alternative treatments focus on proper cleansing, a balanced diet high in fiber, zinc, and raw foods, and avoiding certain triggers like alcohol and processed foods.\n"
     ]
    }
   ],
   "source": [
    "# response = rag_chain.invoke({'input': 'What is cure for back acne?'})\n",
    "# print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e4bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm sorry for any confusion, but the context provided doesn't mention the Samsung Odyssey G7 or its price. It seems to be discussing the cost of Alexander technique lessons, bone grafting procedures, and appendectomy-related costs. If you need help finding the price of Samsung Odyssey G7, I would recommend checking electronics retailers such as Best Buy, Amazon, or directly on Samsung's official website.\n"
     ]
    }
   ],
   "source": [
    "# response = rag_chain.invoke({'input': 'How much does samsung odyssey g7 cost?'})\n",
    "# print(response['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carebot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
