{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d1bd2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\patel\\\\OneDrive\\\\Desktop\\\\Projects\\\\CareBot\\\\CareBot\\\\research'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a300d747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\patel\\\\OneDrive\\\\Desktop\\\\Projects\\\\CareBot\\\\CareBot'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e73d480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5563ef7",
   "metadata": {},
   "source": [
    "Extracting the Data (Gale Encyclopedia of Medicine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3125fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                              glob='*.pdf',\n",
    "                              loader_cls = PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07f58ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(data = 'data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a024d390",
   "metadata": {},
   "source": [
    "Chunking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2125173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_chunking(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 800, chunk_overlap = 80)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9431c99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the text chunks: 3900\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_chunking(extracted_data)\n",
    "print('Length of the text chunks:', len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c79b2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def donwload_huggingface_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name= 'sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f103d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = donwload_huggingface_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "371ff449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length : 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello World!\")\n",
    "print('length :' , len(query_result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9512f2b4",
   "metadata": {},
   "source": [
    "Creating Indexes using pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b04a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n",
    "\n",
    "\n",
    "pc = Pinecone(api_key = PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"carebot\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric = 'cosine',\n",
    "        spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# address the dimension dynamicc....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11825745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "load_dotenv()\n",
    "os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY\n",
    "# OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "# os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')\n",
    "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff94274",
   "metadata": {},
   "source": [
    "Creating Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e13d8856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vs = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ce84ebc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HuggingFaceCrossEncoder' from 'langchain_community.document_transformers' (c:\\Users\\patel\\anaconda3\\envs\\carebot\\lib\\site-packages\\langchain_community\\document_transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ====== RERANKER SETUP (WORKING FOR ALL LANGCHAIN V1.x) ======\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceCrossEncoder\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_compressors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DocumentCompressorPipeline\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ContextualCompressionRetriever\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'HuggingFaceCrossEncoder' from 'langchain_community.document_transformers' (c:\\Users\\patel\\anaconda3\\envs\\carebot\\lib\\site-packages\\langchain_community\\document_transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# ====== RERANKER SETUP (WORKING FOR ALL LANGCHAIN V1.x) ======\n",
    "from langchain_community.document_transformers import HuggingFaceCrossEncoder\n",
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "# Step 1: Base retriever from Pinecone\n",
    "base_retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 10}  # get top 10 candidates first\n",
    ")\n",
    "\n",
    "# Step 2: Local cross-encoder reranker (NO API USE)\n",
    "reranker = HuggingFaceCrossEncoder(\n",
    "    model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "# Step 3: Reranking pipeline\n",
    "compressor = DocumentCompressorPipeline(\n",
    "    transformers=[reranker]\n",
    ")\n",
    "\n",
    "# Step 4: Final reranked retriever\n",
    "retriever = ContextualCompressionRetriever(\n",
    "    base_retriever=base_retriever,\n",
    "    base_document_compressor=compressor\n",
    ")\n",
    "\n",
    "print(\"Reranker loaded. Using reranked retriever.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeea547c",
   "metadata": {},
   "source": [
    "Loading the Vector Database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87200edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x18003e3ef50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "vs = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")\n",
    "vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc2b23a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vs.as_retriever(search_type='similarity', search_kwargs={'k':3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d54fa8",
   "metadata": {},
   "source": [
    "Trial of the search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d10e622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='35ac5c5b-2f93-4556-ab7f-c3aae5d2ddc0', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 39.0, 'page_label': '40', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'data\\\\Medical_book.pdf', 'total_pages': 637.0}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 226\\nAcne\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 26'),\n",
       " Document(id='8e23d5b0-8be5-4563-bd66-d7aba55e878c', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 39.0, 'page_label': '40', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'data\\\\Medical_book.pdf', 'total_pages': 637.0}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 226\\nAcne\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 26'),\n",
       " Document(id='13da37c6-f093-49c7-82af-3f4b572425c8', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 37.0, 'page_label': '38', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'data\\\\Medical_book.pdf', 'total_pages': 637.0}, page_content='Acidosis see Respiratory acidosis; Renal\\ntubular acidosis; Metabolic acidosis\\nAcne\\nDefinition\\nAcne is a common skin disease characterized by\\npimples on the face, chest, and back. It occurs when the\\npores of the skin become clogged with oil, dead skin\\ncells, and bacteria.\\nDescription\\nAcne vulgaris, the medical term for common acne, is\\nthe most common skin disease. It affects nearly 17 million\\npeople in the United States. While acne can arise at any')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = retriever.invoke('What is back Acne?')\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2296eb0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d7a5af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patel\\anaconda3\\envs\\carebot\\lib\\site-packages\\google\\api_core\\_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.19) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\patel\\AppData\\Local\\Temp\\ipykernel_52580\\2281370533.py:35: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "# from langchain_huggingface.chat_models.huggingface import ChatHuggingFace\n",
    "# from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "# from langchain_core.prompts import PromptTemplate\n",
    "# from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "# huggingface_repo_id = \"openai/gpt-oss-20b\"\n",
    "\n",
    "# def load_llm(huggingface_repo_id):\n",
    "#     llm = HuggingFaceEndpoint(\n",
    "#         repo_id = huggingface_repo_id,\n",
    "#         huggingfacehub_api_token=HF_TOKEN,\n",
    "#         task='conversational',  \n",
    "#         max_new_tokens = 256,\n",
    "#         temperature = 0.3           \n",
    "#     )\n",
    "#     return llm\n",
    "\n",
    "# chat = ChatHuggingFace(llm = load_llm(huggingface_repo_id))\n",
    "\n",
    "#genai\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",      \n",
    "    temperature=0.3,\n",
    "    max_output_tokens=512,\n",
    "    google_api_key=GOOGLE_API_KEY  \n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",   \n",
    "    return_messages=True,\n",
    "    output_key=\"answer\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff812376",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt =\"\"\"You are an assistant for the question answer tasks. Use the following pieces of retrieved context to answer the question. If you don't \n",
    "    know the asnwer, say that you don't know. Don't provide anything out of the given context. Use three sentences maximum and keep the answer concise. \\n\\n\n",
    "    \n",
    "    Chat history: {chat_history}\n",
    "    Context : {context}\n",
    "    Question : {question}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=system_prompt,\n",
    "    input_variables=[\"chat_history\", \"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d29ddc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "conv_rag_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    combine_docs_chain_kwargs={\"prompt\": prompt},\n",
    "    return_source_documents=True,\n",
    "    get_chat_history=lambda h: h  # h is a list of messages; we pass it straight to {chat_history}\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "# model = load_llm()\n",
    "\n",
    "# def get_answer(query, context):\n",
    "#     \"\"\"Function to get answer from the model using context\"\"\"\n",
    "#     prompt = f\"\"\"Context: {context}\n",
    "    \n",
    "# Question: {query}\n",
    "\n",
    "# Answer the question based on the context above. Keep it concise and within 3 sentences. If you can't find the answer in the context, say \"I don't know\".\"\"\"\n",
    "    \n",
    "#     response = model.generate_content(prompt)\n",
    "#     return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e3a2a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is acne?\n",
      "Answer: Acne is the general name given to a skin disorder in which the sebaceous glands become inflamed. It is also referred to as Acne vulgaris.\n",
      "\n",
      "--- Source 1 ---\n",
      "data\\Medical_book.pdf | page: 39.0\n",
      "GALE ENCYCLOPEDIA OF MEDICINE 226\n",
      "Acne\n",
      "GEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 26 ...\n",
      "\n",
      "--- Source 2 ---\n",
      "data\\Medical_book.pdf | page: 39.0\n",
      "GALE ENCYCLOPEDIA OF MEDICINE 226\n",
      "Acne\n",
      "GEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 26 ...\n",
      "\n",
      "--- Source 3 ---\n",
      "data\\Medical_book.pdf | page: 38.0\n",
      "GALE ENCYCLOPEDIA OF MEDICINE 2 25\n",
      "Acne\n",
      "Acne vulgaris affecting a womanâ€™s face. Acne is the general\n",
      "name given to a skin disorder in which the sebaceous\n",
      "glands become inflamed. (Photograph by Biophoto Associ-\n",
      "ates, Photo Researchers, Inc. Reproduced by permission.)\n",
      "GEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 25 ...\n"
     ]
    }
   ],
   "source": [
    "# Simple one-shot test using conv_rag_chain\n",
    "query = \"What is acne?\"\n",
    "\n",
    "result = conv_rag_chain.invoke({\"question\": query})\n",
    "\n",
    "print(\"Question:\", query)\n",
    "print(\"Answer:\", result[\"answer\"])\n",
    "\n",
    "# Optional: see what documents were used\n",
    "for i, doc in enumerate(result[\"source_documents\"], start=1):\n",
    "    print(f\"\\n--- Source {i} ---\")\n",
    "    print(doc.metadata.get(\"source\", \"unknown\"), \"| page:\", doc.metadata.get(\"page\"))\n",
    "    print(doc.page_content[:500], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcd30d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = [\n",
    "    {\n",
    "        \"question\": \"What is achalasia?\",\n",
    "        \"reference\": (\n",
    "            \"Achalasia is a disorder of the esophagus that prevents normal swallowing. \"\n",
    "            \"The lower esophageal sphincter fails to relax properly, blocking food from entering the stomach.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What causes achalasia?\",\n",
    "        \"reference\": (\n",
    "            \"Achalasia is caused by degeneration of the nerve cells that normally signal the esophageal sphincter to relax. \"\n",
    "            \"The exact cause is unknown, but autoimmune disease or hidden infection is suspected.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the main symptoms of achalasia?\",\n",
    "        \"reference\": (\n",
    "            \"Symptoms include dysphagia for liquids and solids, sensation of food getting stuck, chest pain resembling angina, \"\n",
    "            \"heartburn, difficulty belching, nighttime coughing, and recurrent pneumonia.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is amyloidosis?\",\n",
    "        \"reference\": (\n",
    "            \"Amyloidosis is a progressive, incurable metabolic disease in which abnormal amyloid proteins accumulate in organs \"\n",
    "            \"or body systems, impairing their function and potentially causing organ failure.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the major types of amyloidosis?\",\n",
    "        \"reference\": (\n",
    "            \"Major types include primary systemic amyloidosis, secondary amyloidosis from chronic infection or inflammation, \"\n",
    "            \"familial or hereditary amyloidosis, and an amyloidosis associated with Alzheimer's disease.\"\n",
    "        )\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dbb4037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "\n",
    "def normalize_answer(s: str) -> str:\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[^a-z0-9\\s]', ' ', s)\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "def ngram_counts(tokens, n):\n",
    "    return {tuple(tokens[i:i+n]): 1 for i in range(len(tokens)-n+1)}\n",
    "\n",
    "def compute_bleu(pred: str, ref: str) -> float:\n",
    "    pred_tokens = normalize_answer(pred).split()\n",
    "    ref_tokens = normalize_answer(ref).split()\n",
    "\n",
    "    if not pred_tokens or not ref_tokens:\n",
    "        return 0.0\n",
    "\n",
    "    precisions = []\n",
    "    for n in range(1, 5):  # up to 4-gram BLEU\n",
    "        pred_ngrams = ngram_counts(pred_tokens, n)\n",
    "        ref_ngrams = ngram_counts(ref_tokens, n)\n",
    "\n",
    "        match = sum(1 for ng in pred_ngrams if ng in ref_ngrams)\n",
    "        total = max(len(pred_tokens) - n + 1, 1)\n",
    "        precisions.append(match / total)\n",
    "\n",
    "    # geometric mean\n",
    "    score = math.exp(sum(math.log(p + 1e-9) for p in precisions) / 4)\n",
    "\n",
    "    # brevity penalty\n",
    "    ref_len = len(ref_tokens)\n",
    "    pred_len = len(pred_tokens)\n",
    "    if pred_len >= ref_len:\n",
    "        bp = 1\n",
    "    else:\n",
    "        bp = math.exp(1 - ref_len / pred_len)\n",
    "\n",
    "    return bp * score\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def exact_match(pred: str, ref: str) -> bool:\n",
    "    return normalize_answer(pred) == normalize_answer(ref)\n",
    "\n",
    "def fuzzy_match(pred: str, ref: str, threshold=0.75):\n",
    "    return SequenceMatcher(None, normalize_answer(pred), normalize_answer(ref)).ratio() >= threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "532abd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "def evaluate_chatbot(\n",
    "    examples,\n",
    "    max_samples=None,\n",
    "    sleep_s=12 \n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate Carebot on a small set of Q/A pairs.\n",
    "\n",
    "    examples: list of {\"question\": ..., \"reference\": ...}\n",
    "    max_samples: cap number of evaluated examples (optional)\n",
    "    sleep_s: seconds to sleep between calls to avoid rate limits\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    n = len(examples) if max_samples is None else min(len(examples), max_samples)\n",
    "\n",
    "    for i in range(n):\n",
    "        q = examples[i][\"question\"]\n",
    "        ref = examples[i][\"reference\"]\n",
    "\n",
    "        print(f\"\\n[{i+1}/{n}] Question: {q}\")\n",
    "        # === Model call ===\n",
    "        out = conv_rag_chain.invoke({\"question\": q})\n",
    "        pred = out[\"answer\"]\n",
    "\n",
    "        # === Metrics ===\n",
    "        bleu = compute_bleu(pred, ref)\n",
    "        em = exact_match(pred, ref)\n",
    "        fm = fuzzy_match(pred, ref)\n",
    "\n",
    "        results.append({\n",
    "            \"question\": q,\n",
    "            \"reference\": ref,\n",
    "            \"prediction\": pred,\n",
    "            \"bleu\": bleu,\n",
    "            \"exact_match\": em,\n",
    "            \"fuzzy_match\": fm\n",
    "        })\n",
    "\n",
    "        print(\"Prediction:\", pred[:300].replace(\"\\n\", \" \"), \"...\")\n",
    "        print(\"Reference :\", ref[:300].replace(\"\\n\", \" \"), \"...\")\n",
    "        print(f\"BLEU={bleu:.3f}, exact={em}, fuzzy={fm}\")\n",
    "\n",
    "        # Sleep to stay under RPM limits\n",
    "        if sleep_s and i < n - 1:\n",
    "            time.sleep(sleep_s)\n",
    "\n",
    "    # === Aggregate scores ===\n",
    "    avg_bleu = sum(r[\"bleu\"] for r in results) / len(results)\n",
    "    acc_exact = sum(1 for r in results if r[\"exact_match\"]) / len(results)\n",
    "    acc_fuzzy = sum(1 for r in results if r[\"fuzzy_match\"]) / len(results)\n",
    "\n",
    "    print(\"\\n=== Overall metrics ===\")\n",
    "    print(f\"Average BLEU: {avg_bleu:.3f}\")\n",
    "    print(f\"Exact-match accuracy: {acc_exact:.3f}\")\n",
    "    print(f\"Fuzzy-match accuracy: {acc_fuzzy:.3f}\")\n",
    "\n",
    "    metrics = {\n",
    "        \"avg_bleu\": avg_bleu,\n",
    "        \"exact_acc\": acc_exact,\n",
    "        \"fuzzy_acc\": acc_fuzzy\n",
    "    }\n",
    "    return results, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941973b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/5] Question: What is achalasia?\n",
      "Prediction: Achalasia is a disorder of the esophagus that prevents normal swallowing. It affects the esophagus, which is the tube that carries swallowed food from the back of the throat down into the stomach. ...\n",
      "Reference : Achalasia is a disorder of the esophagus that prevents normal swallowing. The lower esophageal sphincter fails to relax properly, blocking food from entering the stomach. ...\n",
      "BLEU=0.333, exact=False, fuzzy=False\n",
      "\n",
      "[2/5] Question: What causes achalasia?\n",
      "Prediction: Achalasia is caused by the degeneration of nerve cells that normally signal the brain to relax the esophageal sphincter. This degeneration prevents the esophageal sphincter from relaxing, interrupting normal peristalsis. ...\n",
      "Reference : Achalasia is caused by degeneration of the nerve cells that normally signal the esophageal sphincter to relax. The exact cause is unknown, but autoimmune disease or hidden infection is suspected. ...\n",
      "BLEU=0.317, exact=False, fuzzy=False\n",
      "\n",
      "[3/5] Question: What are the main symptoms of achalasia?\n",
      "Prediction: The most common symptom of achalasia is dysphagia, or difficulty swallowing, affecting both liquid and solid foods. Individuals often experience chest pain, heartburn, and difficulty belching. Other symptoms may include a nighttime cough or recurrent pneumonia caused by food passing into the lower a ...\n",
      "Reference : Symptoms include dysphagia for liquids and solids, sensation of food getting stuck, chest pain resembling angina, heartburn, difficulty belching, nighttime coughing, and recurrent pneumonia. ...\n",
      "BLEU=0.000, exact=False, fuzzy=False\n",
      "\n",
      "[4/5] Question: What is amyloidosis?\n",
      "Prediction: Amyloidosis is a progressive, incurable, metabolic disease characterized by abnormal deposits of protein in one or more organs or body systems. It occurs when accumulated amyloid deposits impair normal body function, which can lead to organ failure or death. Amyloid proteins are manufactured by malf ...\n",
      "Reference : Amyloidosis is a progressive, incurable metabolic disease in which abnormal amyloid proteins accumulate in organs or body systems, impairing their function and potentially causing organ failure. ...\n",
      "BLEU=0.203, exact=False, fuzzy=False\n",
      "\n",
      "[5/5] Question: What are the major types of amyloidosis?\n",
      "Prediction: The major forms of amyloidosis are primary systemic, secondary, and familial or hereditary amyloidosis. There is also another form of amyloidosis associated with Alzheimer's disease. At least 15 types of amyloidosis have been identified, each linked to deposits of a different kind of protein. ...\n",
      "Reference : Major types include primary systemic amyloidosis, secondary amyloidosis from chronic infection or inflammation, familial or hereditary amyloidosis, and an amyloidosis associated with Alzheimer's disease. ...\n",
      "BLEU=0.173, exact=False, fuzzy=False\n",
      "\n",
      "=== Overall metrics ===\n",
      "Average BLEU: 0.205\n",
      "Exact-match accuracy: 0.000\n",
      "Fuzzy-match accuracy: 0.000\n"
     ]
    }
   ],
   "source": [
    "results, metrics = evaluate_chatbot(\n",
    "    eval_data,\n",
    "    max_samples=5,\n",
    "    sleep_s=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c97da109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness\n",
    "from ragas.run_config import RunConfig\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd8f3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "ST_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "st_model = SentenceTransformer(ST_MODEL_NAME)\n",
    "hf_embed = HuggingFaceEmbeddings(model_name=ST_MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0afaa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patel\\AppData\\Local\\Temp\\ipykernel_52580\\3003647697.py:3: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm_for_ragas = ChatOllama(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "llm_for_ragas = ChatOllama(\n",
    "    model=\"llama3.1\",   # or \"llama3.1:8b\" / whatever tag you pulled\n",
    "    temperature=0.0     # deterministic, good for evaluation\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db7e545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "\n",
    "llm_for_ragas = ChatOllama(\n",
    "    model=\"llama3.1\",   # or llama3.2, llama2, etc.\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee757060",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = RunConfig(\n",
    "    max_workers=1,   # 1 job at a time to keep things simple\n",
    "    timeout=120\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fff6104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def run_chatbot_eval_and_collect_ragas_data(\n",
    "    eval_data,\n",
    "    max_samples=5,\n",
    "    sleep_s=5  # small pause between chatbot calls (Gemini)\n",
    "):\n",
    "    \"\"\"\n",
    "    Uses conv_rag_chain (Gemini) to answer eval questions\n",
    "    and collects data for ragas faithfulness.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    ragas_records = []\n",
    "\n",
    "    n = min(len(eval_data), max_samples)\n",
    "\n",
    "    for i in range(n):\n",
    "        q = eval_data[i][\"question\"]\n",
    "        gt = eval_data[i][\"reference\"]\n",
    "\n",
    "        print(f\"\\n[{i+1}/{n}] Question: {q}\")\n",
    "        out = conv_rag_chain.invoke({\"question\": q})\n",
    "\n",
    "        pred = out[\"answer\"]\n",
    "        ctxs = [d.page_content for d in out[\"source_documents\"]]\n",
    "\n",
    "        print(\"Prediction:\", pred[:200].replace(\"\\n\", \" \"), \"...\")\n",
    "        print(\"Reference :\", gt[:200].replace(\"\\n\", \" \"), \"...\")\n",
    "\n",
    "        # store for your own offline metrics (optional)\n",
    "        results.append({\n",
    "            \"question\": q,\n",
    "            \"reference\": gt,\n",
    "            \"prediction\": pred,\n",
    "        })\n",
    "\n",
    "        # store for ragas\n",
    "        ragas_records.append({\n",
    "            \"question\": q,\n",
    "            \"answer\": pred,\n",
    "            \"contexts\": ctxs,\n",
    "            \"ground_truth\": gt,\n",
    "        })\n",
    "\n",
    "        if sleep_s and i < n - 1:\n",
    "            time.sleep(sleep_s)\n",
    "\n",
    "    ragas_dataset = Dataset.from_list(ragas_records)\n",
    "    return results, ragas_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c756c1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/5] Question: What is achalasia?\n",
      "Prediction: Achalasia is a disorder of the esophagus that prevents normal swallowing. It affects the tube that carries swallowed food from the back of the throat down into the stomach. ...\n",
      "Reference : Achalasia is a disorder of the esophagus that prevents normal swallowing. The lower esophageal sphincter fails to relax properly, blocking food from entering the stomach. ...\n",
      "\n",
      "[2/5] Question: What causes achalasia?\n",
      "Prediction: Achalasia is caused by the degeneration of nerve cells that normally signal the brain to relax the esophageal sphincter. These nerve cells are responsible for allowing food to enter the stomach. The u ...\n",
      "Reference : Achalasia is caused by degeneration of the nerve cells that normally signal the esophageal sphincter to relax. The exact cause is unknown, but autoimmune disease or hidden infection is suspected. ...\n",
      "\n",
      "[3/5] Question: What are the main symptoms of achalasia?\n",
      "Prediction: The most common symptom of achalasia is dysphagia, or difficulty swallowing, for both liquid and solid foods, often feeling that food \"gets stuck.\" Other symptoms include chest pain, heartburn, and di ...\n",
      "Reference : Symptoms include dysphagia for liquids and solids, sensation of food getting stuck, chest pain resembling angina, heartburn, difficulty belching, nighttime coughing, and recurrent pneumonia. ...\n",
      "\n",
      "[4/5] Question: What is amyloidosis?\n",
      "Prediction: Amyloidosis is a progressive, incurable, metabolic disease characterized by abnormal deposits of protein in one or more organs or body systems. It occurs when accumulated amyloid deposits impair norma ...\n",
      "Reference : Amyloidosis is a progressive, incurable metabolic disease in which abnormal amyloid proteins accumulate in organs or body systems, impairing their function and potentially causing organ failure. ...\n",
      "\n",
      "[5/5] Question: What are the major types of amyloidosis?\n",
      "Prediction: The major forms of amyloidosis are primary systemic, secondary, and familial or hereditary amyloidosis. There is also another form of amyloidosis associated with Alzheimer's disease. ...\n",
      "Reference : Major types include primary systemic amyloidosis, secondary amyloidosis from chronic infection or inflammation, familial or hereditary amyloidosis, and an amyloidosis associated with Alzheimer's disea ...\n"
     ]
    }
   ],
   "source": [
    "results, ragas_dataset = run_chatbot_eval_and_collect_ragas_data(\n",
    "    eval_data,\n",
    "    max_samples=5,\n",
    "    sleep_s=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9a402eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [02:32<00:00, 30.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 0.9000}\n"
     ]
    }
   ],
   "source": [
    "faith_result = evaluate(\n",
    "    ragas_dataset,\n",
    "    metrics=[faithfulness],   # only faithfulness\n",
    "    llm=llm_for_ragas,        # ðŸ”¥ Llama here, not Gemini\n",
    "    embeddings=hf_embed,\n",
    "    run_config=run_config\n",
    ")\n",
    "\n",
    "print(faith_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carebot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
